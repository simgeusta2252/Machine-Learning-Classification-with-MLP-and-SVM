# Machine Learning Classification with MLP and SVM

## ğŸ” Proje Ã–zeti
Bu projede, iki farklÄ± ikili sÄ±nÄ±flandÄ±rma veri seti (**HIGGS** ve **RCV1**) Ã¼zerinde  
**Ã‡ok KatmanlÄ± AlgÄ±layÄ±cÄ± (MLP)** ve **Destek VektÃ¶r Makineleri (SVM)** algoritmalarÄ± incelenmiÅŸtir.

Projenin temel amacÄ±, makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ±n:
- nasÄ±l Ã¶ÄŸrendiÄŸini,
- optimizasyon sÃ¼recinin nasÄ±l iÅŸlediÄŸini,
- hiperparametrelerin modele etkisini  

hazÄ±r kÃ¼tÃ¼phaneler kullanmadan, **yalnÄ±zca NumPy ile sÄ±fÄ±rdan implementasyon** yaparak anlamaktÄ±r.

---

## ğŸ“Š KullanÄ±lan Veri Setleri

### ğŸ”¹ HIGGS Veri Seti
- 28 adet sayÄ±sal Ã¶zellik
- DoÄŸrusal olmayan iliÅŸkiler iÃ§erir
- Ä°kili sÄ±nÄ±flandÄ±rma problemi

### ğŸ”¹ RCV1 Veri Seti
- 47.236 boyutlu, seyrek (sparse) Ã¶zellik uzayÄ±
- Metin tabanlÄ± (TF-IDF) veri
- YÃ¼ksek boyutlu ikili sÄ±nÄ±flandÄ±rma problemi

Her iki veri seti de:
- eÄŸitim (train),
- doÄŸrulama (validation),
- test  

kÃ¼melerine ayrÄ±lmÄ±ÅŸtÄ±r.

---

## ğŸ§  YÃ¶ntem
Bu projede tÃ¼m modeller:
- ileri besleme (forward propagation),
- geri yayÄ±lÄ±m (backpropagation),
- gradyan hesaplamalarÄ±,
- aÄŸÄ±rlÄ±k gÃ¼ncellemeleri  

**NumPy kullanÄ±larak sÄ±fÄ±rdan** geliÅŸtirilmiÅŸtir.

AmaÃ§, modelin bir *â€œkara kutuâ€* gibi deÄŸil, matematiksel olarak nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrudan gÃ¶zlemlemektir.  
TensorFlow, PyTorch veya scikit-learn gibi hazÄ±r kÃ¼tÃ¼phaneler **kullanÄ±lmamÄ±ÅŸtÄ±r**.

---

## ğŸ¤– KullanÄ±lan Modeller

### ğŸ”¹ Ã‡ok KatmanlÄ± AlgÄ±layÄ±cÄ± (MLP)
- Tam baÄŸlantÄ±lÄ± (fully connected) sinir aÄŸÄ±
- Backpropagation ile eÄŸitilmiÅŸtir
- Test edilen aktivasyon fonksiyonlarÄ±:
  - Sigmoid
  - Tanh
  - ReLU

### ğŸ”¹ Destek VektÃ¶r Makineleri (SVM)
- Lineer SVM modeli
- **Pegasos algoritmasÄ±** kullanÄ±larak implementasyon yapÄ±lmÄ±ÅŸtÄ±r
- YÃ¼ksek boyutlu ve seyrek veri setleri iÃ§in uygundur

### ğŸ”¹ Stacking (Hibrit Model)
- MLP ve SVM modellerinin Ã§Ä±ktÄ±larÄ± birleÅŸtirilmiÅŸtir
- Meta-model olarak Logistic Regression kullanÄ±lmÄ±ÅŸtÄ±r
- AmaÃ§, model varyansÄ±nÄ± azaltmak ve daha stabil sonuÃ§lar elde etmektir

---

## âš™ï¸ Deneysel Ã‡alÄ±ÅŸmalar
AÅŸaÄŸÄ±daki hiperparametrelerin modele etkisi incelenmiÅŸtir:

- **Optimizasyon AlgoritmalarÄ±:** SGD, Momentum, RMSprop, Adam  
- **Learning Rate DeÄŸerleri:** 0.1, 0.01, 0.001  
- **Aktivasyon FonksiyonlarÄ±:** Sigmoid, Tanh, ReLU  

EÄŸitim sÃ¼reci boyunca **lossâ€“epoch grafikleri** analiz edilmiÅŸtir.

---

## ğŸ“ˆ SonuÃ§lar ve GÃ¶zlemler
- Adam ve RMSprop, SGDâ€™ye gÃ¶re daha hÄ±zlÄ± yakÄ±nsama saÄŸlamÄ±ÅŸtÄ±r
- Sigmoid aktivasyonda **vanishing gradient** problemi gÃ¶zlemlenmiÅŸtir
- Learning rate = **0.01**, en dengeli sonuÃ§larÄ± vermiÅŸtir
- HIGGS veri setinde MLP, SVMâ€™ye kÄ±yasla daha iyi performans gÃ¶stermiÅŸtir
- Stacking yÃ¶ntemi, model performansÄ±nÄ± ve kararlÄ±lÄ±ÄŸÄ±nÄ± artÄ±rmÄ±ÅŸtÄ±r

**DeÄŸerlendirme metrikleri:**
- Accuracy
- F1-Score
- Confusion Matrix
